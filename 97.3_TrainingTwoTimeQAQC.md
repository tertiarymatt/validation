QA/QC for Validation Training Data
================
MS Patterson, <tertiarymatt@gmail.com>
January 22, 2019

Set working directory to where data is being stored. + setwd

``` r
setwd("~/R/projects/validation")
```

### Required packages

``` r
library(tidyverse)
```

    ## -- Attaching packages -------------------------------------------------- tidyverse 1.2.1 --

    ## v ggplot2 3.1.0     v purrr   0.2.5
    ## v tibble  1.4.2     v dplyr   0.7.8
    ## v tidyr   0.8.2     v stringr 1.3.1
    ## v readr   1.2.1     v forcats 0.3.0

    ## -- Conflicts ----------------------------------------------------- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(irr)
```

    ## Loading required package: lpSolve

``` r
library(knitr)
source("00_functions.R")
```

### Import Data

``` r
kim <- read_csv("data/ceo-two-time-training-1.2-plot-data-2019-01-23.csv")
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   SHAPE = col_character(),
    ##   FLAGGED = col_logical(),
    ##   USER_ID = col_character(),
    ##   ANALYSIS_DURATION = col_logical(),
    ##   COLLECTION_TIME = col_datetime(format = ""),
    ##   PL_NIVEL2 = col_character()
    ## )

    ## See spec(...) for full column specifications.

``` r
steve <- read_csv("data/ceo-two-time-training-1.1-plot-data-2019-01-23.csv")
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   SHAPE = col_character(),
    ##   FLAGGED = col_logical(),
    ##   USER_ID = col_character(),
    ##   ANALYSIS_DURATION = col_logical(),
    ##   COLLECTION_TIME = col_datetime(format = ""),
    ##   PL_NIVEL2 = col_character()
    ## )
    ## See spec(...) for full column specifications.

``` r
crossData <- rbind(kim, steve)
```

### Process data into form that can be used for irr

Provide overview of the process.

``` r
#time one plot data
time1 <- crossData[,16:34]

#time two plot data
time2 <- crossData[,35:53]

#create metadata data table. Use the colnames to find them and adjust columns.
metadata <- crossData[,1:15]

#add metadata to the time tables.
time1 <- bind_cols(metadata, time1)
time2 <-  bind_cols(metadata, time2)

# class names need to be pulled and cleaned up.
colnames(time1)
```

    ##  [1] "PLOT_ID"                             
    ##  [2] "CENTER_LON"                          
    ##  [3] "CENTER_LAT"                          
    ##  [4] "SIZE_M"                              
    ##  [5] "SHAPE"                               
    ##  [6] "FLAGGED"                             
    ##  [7] "ANALYSES"                            
    ##  [8] "SAMPLE_POINTS"                       
    ##  [9] "USER_ID"                             
    ## [10] "ANALYSIS_DURATION"                   
    ## [11] "COLLECTION_TIME"                     
    ## [12] "PL_LONGITUDE"                        
    ## [13] "PL_LATITUDE"                         
    ## [14] "PL_PLOTID"                           
    ## [15] "PL_NIVEL2"                           
    ## [16] "CURRENT COVER:PRIMARY TREE"          
    ## [17] "CURRENT COVER:SECONDARY TREE"        
    ## [18] "CURRENT COVER:PLANTATION TREE"       
    ## [19] "CURRENT COVER:MANGROVE"              
    ## [20] "CURRENT COVER:HERBACEOUS VEGETATION" 
    ## [21] "CURRENT COVER:SHRUB VEGETATION"      
    ## [22] "CURRENT COVER:PARAMO VEGETATION"     
    ## [23] "CURRENT COVER:CROPS"                 
    ## [24] "CURRENT COVER:NATURAL WATER"         
    ## [25] "CURRENT COVER:ARTIFICIAL WATER"      
    ## [26] "CURRENT COVER:WETLAND VEGETATION"    
    ## [27] "CURRENT COVER:HOUSING STRUCTURE"     
    ## [28] "CURRENT COVER:INFRASTRUCTURE"        
    ## [29] "CURRENT COVER:ROADS AND LOTS"        
    ## [30] "CURRENT COVER:SETTLEMENT VEGETATION" 
    ## [31] "CURRENT COVER:BARE GROUND"           
    ## [32] "CURRENT COVER:SNOW/ICE"              
    ## [33] "CURRENT COVER:OTHER"                 
    ## [34] "CURRENT COVER:CLOUDS/UNINTERPRETABLE"

``` r
# create class column object to use in script.
# If the structure of the data changes this MUST be updated.
classCol <- c(16:34)

classes <- colnames(time1[classCol]) %>% 
    str_split(., coll(":"), simplify = TRUE) %>% 
    .[,2] %>% 
    gsub(" ", "_", .) %>% 
    gsub("/", "_", .)

colnames(time1)[classCol] <- classes
colnames(time2)[classCol] <- classes

#verify the tables have the same names
colnames(time1) == colnames(time2)
```

    ##  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
    ## [15] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
    ## [29] TRUE TRUE TRUE TRUE TRUE TRUE

### CEO Point Table Reclassification

Use \`addTopClasses()\`\` to take a raw plot table produced by Collect Earth Online, and returns that table with a Primary and Secondary class field added.

``` r
time1 <- addTopClasses(time1, plotfield = 1, flagfield = 6, 
                                             classfields = classCol)

time2 <- addTopClasses(time2, plotfield = 1, flagfield = 6, 
                                             classfields = classCol)
```

Then use primary and/or secondary classes and threshold values to convert to end classification.

### Level 1 and Level 2 LULC classes

Next steps: add code to convert to level 1 and level 2 classes, and test agreement/consistency at that level. Because the data is collected a finer level of detail than either Level 1 or Level 2, Level 2 is produced first.

### Reclass table into classes using case\_when and dplyr.

``` r
# Adding the Level 2 Classes. 
reclassedTime1 <- addLevel2(time1)
reclassedTime2 <- addLevel2(time2)
```

#### Level 1 LULC Conversions:

``` r
# Add level one classes. 
reclassedTime1 <- addLevel1(reclassedTime1)
reclassedTime2 <- addLevel1(reclassedTime2)


# Process data into form that can be used for irr
# to do this, need to prepare a list of data frames with values for each class
# this is then fed to the irr functions. 

classes <- colnames(reclassedTime1)[16:38]

# Matrices for time 1
cross_tables1 <- rep(list(NA),length(classes))
names(cross_tables1) <- classes

for (m in 1:length(cross_tables1)) {
    cross_tables1[[m]] <- select(reclassedTime1, "USER_ID", "PLOT_ID", classes[m]) %>%
        spread(., "USER_ID", classes[m]) %>%
        .[,-1] %>%
        na.omit(.) %>% 
        as.matrix(.)
}


# Matrices for time 2
cross_tables2 <- rep(list(NA),length(classes))
names(cross_tables2) <- classes

for (m in 1:length(cross_tables2)) {
    cross_tables2[[m]] <- select(reclassedTime2, "USER_ID", "PLOT_ID", classes[m]) %>%
        spread(., "USER_ID", classes[m]) %>%
        .[,-1] %>%
        na.omit(.) %>% 
        as.matrix(.)
}
```

### Calculate Metrics of Agreement

**Iota** is used to calculate overall agreement between raters, and represents an overall look at how close they agree. A more granular approach is necessary to improve agreement, but iota provides a useful summary.

#### Citations

1.  Conger, A.J. (1980). Integration and generalisation of Kappas for multiple raters. Psychological Bulletin, 88, 322-328.
2.  Janson, H., & Olsson, U. (2001). A measure of agreement for interval or nominal multivariate observations. Educational and Psychological Measurement, 61, 277-289.

``` r
crossval_iota1q <- iota(cross_tables1[1:19], scaledata = "q")
crossval_iota1n <- iota(cross_tables1[20:23], scaledata = "n")
crossval_iota1q
```

    ##  iota for quantitative data (19 variables)
    ## 
    ##  Subjects = 55 
    ##    Raters = 2 
    ##      iota = 0.584

``` r
crossval_iota1n
```

    ##  iota for nominal data (4 variables)
    ## 
    ##  Subjects = 55 
    ##    Raters = 2 
    ##      iota = 0.476

``` r
crossval_iota2q <- iota(cross_tables2[1:19], scaledata = "q")
crossval_iota2n <- iota(cross_tables2[20:23], scaledata = "n")
crossval_iota2q
```

    ##  iota for quantitative data (19 variables)
    ## 
    ##  Subjects = 55 
    ##    Raters = 2 
    ##      iota = 0.547

``` r
crossval_iota2n
```

    ##  iota for nominal data (4 variables)
    ## 
    ##  Subjects = 55 
    ##    Raters = 2 
    ##      iota = 0.499

For checking agreement of individual classes, we can use several approaches.
The **intraclass correlation coefficient** and **mean bivariate Pearson's** are two. The ICC is used to measure consistency between two raters, and uses an F-test to test for significance.

#### Citations

1.  Bartko, J.J. (1966). The intraclass correlation coefficient as a measure of reliability. Psychological Reports, 19, 3-11.
2.  McGraw, K.O., & Wong, S.P. (1996), Forming inferences about some intraclass correlation coefficients. Psychological Methods, 1, 30-46.
3.  Shrout, P.E., & Fleiss, J.L. (1979), Intraclass correlation: uses in assessing rater reliability. Psychological Bulletin, 86, 420-428.

``` r
# Intraclass Correlation Coefficient Time 1
cross_icc1 <- list()
for (m in 1:(length(cross_tables1)-4)) {
    cross_icc1[[m]] <- icc(cross_tables1[[m]], model = "oneway", type = "agreement")
}
names(cross_icc1) <- classes[1:19]

# make a "table" from data values in list
icc_values1 <- data_frame(length(classes)-4, 5)
for (m in 1:length(cross_icc1)) {
    icc_values1[m,1] <- names(cross_icc1[m])
    icc_values1[m,2] <- round(cross_icc1[[m]]$value, 4)
    icc_values1[m,3] <- round(cross_icc1[[m]]$lbound, 4)
    icc_values1[m,4] <- round(cross_icc1[[m]]$ubound, 4)
    icc_values1[m,5] <- round(cross_icc1[[m]]$p.value, 4)
}

colnames(icc_values1) <- c("Class", "ICC", "Lower", "Upper", "Pvalue")

# Make a nice table for time 1 values. 
kable(icc_values1)
```

| Class                   |      ICC|    Lower|   Upper|  Pvalue|
|:------------------------|--------:|--------:|-------:|-------:|
| PRIMARY\_TREE           |   0.5581|   0.3471|  0.7157|  0.0000|
| SECONDARY\_TREE         |  -0.0325|  -0.2917|  0.2319|  0.5939|
| PLANTATION\_TREE        |   0.8670|   0.7830|  0.9201|  0.0000|
| MANGROVE                |   0.6625|   0.4848|  0.7879|  0.0000|
| HERBACEOUS\_VEGETATION  |   0.2985|   0.0399|  0.5201|  0.0123|
| SHRUB\_VEGETATION       |   0.5075|   0.2834|  0.6794|  0.0000|
| PARAMO\_VEGETATION      |   0.5343|   0.3169|  0.6987|  0.0000|
| CROPS                   |   0.5510|   0.3381|  0.7107|  0.0000|
| NATURAL\_WATER          |   0.0983|  -0.1678|  0.3515|  0.2343|
| ARTIFICIAL\_WATER       |   1.0000|      NaN|     NaN|  0.0000|
| WETLAND\_VEGETATION     |   1.0000|      NaN|     NaN|  0.0000|
| HOUSING\_STRUCTURE      |   0.8448|   0.7486|  0.9063|  0.0000|
| INFRASTRUCTURE          |      NaN|      NaN|     NaN|     NaN|
| ROADS\_AND\_LOTS        |   0.7496|   0.6070|  0.8457|  0.0000|
| SETTLEMENT\_VEGETATION  |   0.3091|   0.0515|  0.5286|  0.0099|
| BARE\_GROUND            |   0.8241|   0.7170|  0.8933|  0.0000|
| SNOW\_ICE               |   1.0000|      NaN|     NaN|  0.0000|
| OTHER                   |      NaN|      NaN|     NaN|     NaN|
| CLOUDS\_UNINTERPRETABLE |      NaN|      NaN|     NaN|     NaN|

Now that we have the dominant landscape element classes, we can check for agreement between the interpreters on that, in this case just using simple percentages.

``` r
# Get raw percentage agreement on dominant class
round(sum(cross_tables1$Primary[,1] == cross_tables1$Primary[,2]) 
            / nrow(cross_tables1$Primary) * 100, 2)
```

    ## [1] 56.36

``` r
# Get raw percentage agreement on secondary class. 
round(sum(cross_tables1$Secondary[,1] == cross_tables1$Secondary[,2]) 
            / nrow(cross_tables1$Secondary) * 100, 2)
```

    ## [1] 36.36

``` r
# Get raw percentage agreement on level 2 class
round(sum(cross_tables1$LEVEL2[,1] == cross_tables1$LEVEL2[,2]) 
            / nrow(cross_tables1$LEVEL2) * 100, 2)
```

    ## [1] 56.36

``` r
# Get raw percentage agreement on level 1 class. 
round(sum(cross_tables1$LEVEL1[,1] == cross_tables1$LEVEL1[,2]) 
            / nrow(cross_tables1$LEVEL1) * 100, 2)
```

    ## [1] 69.09

``` r
# Intraclass Correlation Coefficient Time 2
cross_icc2 <- list()
for (m in 1:(length(cross_tables2)-4)) {
    cross_icc2[[m]] <- icc(cross_tables2[[m]], model = "oneway", type = "agreement")
}
names(cross_icc2) <- classes[1:19]

# make a "table" from data values in list
icc_values2 <- data_frame(length(classes)-4, 5)
for (m in 1:length(cross_icc2)) {
    icc_values2[m,1] <- names(cross_icc2[m])
    icc_values2[m,2] <- round(cross_icc2[[m]]$value, 4)
    icc_values2[m,3] <- round(cross_icc2[[m]]$lbound, 4)
    icc_values2[m,4] <- round(cross_icc2[[m]]$ubound, 4)
    icc_values2[m,5] <- round(cross_icc2[[m]]$p.value, 4)
}

colnames(icc_values2) <- c("Class", "ICC", "Lower", "Upper", "Pvalue")

# Make a nice table for time 2 values. 
kable(icc_values2)
```

| Class                   |      ICC|    Lower|   Upper|  Pvalue|
|:------------------------|--------:|--------:|-------:|-------:|
| PRIMARY\_TREE           |   0.4411|   0.2028|  0.6305|  0.0003|
| SECONDARY\_TREE         |  -0.0233|  -0.2833|  0.2405|  0.5676|
| PLANTATION\_TREE        |   1.0000|      NaN|     NaN|  0.0000|
| MANGROVE                |   0.6625|   0.4848|  0.7879|  0.0000|
| HERBACEOUS\_VEGETATION  |   0.3013|   0.0430|  0.5224|  0.0116|
| SHRUB\_VEGETATION       |   0.3357|   0.0811|  0.5496|  0.0055|
| PARAMO\_VEGETATION      |   0.5160|   0.2940|  0.6856|  0.0000|
| CROPS                   |   0.5721|   0.3650|  0.7256|  0.0000|
| NATURAL\_WATER          |   0.1998|  -0.0653|  0.4392|  0.0687|
| ARTIFICIAL\_WATER       |   0.9808|   0.9674|  0.9887|  0.0000|
| WETLAND\_VEGETATION     |   1.0000|      NaN|     NaN|  0.0000|
| HOUSING\_STRUCTURE      |   0.9362|   0.8933|  0.9622|  0.0000|
| INFRASTRUCTURE          |      NaN|      NaN|     NaN|     NaN|
| ROADS\_AND\_LOTS        |   0.9575|   0.9284|  0.9749|  0.0000|
| SETTLEMENT\_VEGETATION  |   0.9899|   0.9829|  0.9941|  0.0000|
| BARE\_GROUND            |   0.7223|   0.5679|  0.8278|  0.0000|
| SNOW\_ICE               |   1.0000|      NaN|     NaN|  0.0000|
| OTHER                   |      NaN|      NaN|     NaN|     NaN|
| CLOUDS\_UNINTERPRETABLE |      NaN|      NaN|     NaN|     NaN|

Now that we have the dominant landscape element classes, we can check for agreement between the interpreters on that, in this case just using simple percentages.

``` r
# Get raw percentage agreement on dominant class
round(sum(cross_tables2$Primary[,1] == cross_tables2$Primary[,2]) 
            / nrow(cross_tables2$Primary) * 100, 2)
```

    ## [1] 58.18

``` r
# Get raw percentage agreement on secondary class. 
round(sum(cross_tables2$Secondary[,1] == cross_tables2$Secondary[,2]) 
            / nrow(cross_tables2$Secondary) * 100, 2)
```

    ## [1] 40

``` r
# Get raw percentage agreement on level 2 class
round(sum(cross_tables2$LEVEL2[,1] == cross_tables2$LEVEL2[,2]) 
            / nrow(cross_tables2$LEVEL2) * 100, 2)
```

    ## [1] 56.36

``` r
# Get raw percentage agreement on level 1 class. 
round(sum(cross_tables2$LEVEL1[,1] == cross_tables2$LEVEL1[,2]) 
            / nrow(cross_tables2$LEVEL1) * 100, 2)
```

    ## [1] 72.73

``` r
# Agreement on change. 
 
finalTable <- metadata
finalTable$T1L1 <- reclassedTime1$LEVEL1
finalTable$T1L2 <- reclassedTime1$LEVEL2
finalTable$T2L1 <- reclassedTime2$LEVEL1
finalTable$T2L2 <- reclassedTime2$LEVEL2
finalTable$changeL1 <- finalTable$T1L1 != finalTable$T2L1
finalTable$changeL2 <- finalTable$T1L2 != finalTable$T2L2

# produce final classes
finalTable <- addFinal(finalTable)

# make a little tibble with just the final class, spread by rater
finalAgree <- select(finalTable, "USER_ID", "PLOT_ID", "refClass") %>%
    spread(., "USER_ID", "refClass") %>%
    na.omit(.)

# Get raw percentage agreement on change class
round(sum(finalAgree[,2] == finalAgree[,3]) 
            / nrow(finalAgree) * 100, 2)
```

    ## [1] 50.91
